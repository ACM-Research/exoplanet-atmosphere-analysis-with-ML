{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c60cc6b6",
   "metadata": {},
   "source": [
    "Non-negative least squares regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "314381c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aman/.local/opt/miniconda/envs/exo2/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lazypredict.Supervised import LazyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0474130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.27030e-24 3.07616e-24 5.22539e-24 ... 1.32958e-21 1.33228e-21\n",
      "  1.35562e-21]\n",
      " [1.30267e-20 1.30677e-20 1.31157e-20 ... 3.81686e-20 3.81212e-20\n",
      "  3.80739e-20]\n",
      " [6.26322e-21 6.28294e-21 6.30602e-21 ... 1.83835e-20 1.83606e-20\n",
      "  1.83378e-20]\n",
      " ...\n",
      " [2.18046e-21 2.18672e-21 2.19415e-21 ... 4.09628e-21 4.09113e-21\n",
      "  4.08599e-21]\n",
      " [8.45625e-21 8.48075e-21 8.50976e-21 ... 1.65705e-20 1.65496e-20\n",
      "  1.65289e-20]\n",
      " [9.18122e-27 9.43401e-27 1.16085e-26 ... 4.02891e-22 4.05835e-22\n",
      "  4.14389e-22]]\n"
     ]
    }
   ],
   "source": [
    "x_data = np.loadtxt(\"dataset/x_dataTrain.txt\")\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01717c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.44779525e-02 3.63563344e-01 3.93226327e-01 ... 3.84039400e-03\n",
      "  1.04632279e-03 8.05759487e-06]\n",
      " [4.16023007e-02 1.98831946e-01 3.19697149e-01 ... 1.58676888e-04\n",
      "  2.70865681e-04 6.98852685e-06]\n",
      " [3.25809662e-02 3.30184164e-01 2.25277622e-01 ... 3.64259914e-04\n",
      "  1.77938880e-05 5.15590766e-06]\n",
      " ...\n",
      " [6.00137545e-03 2.25446819e-01 2.36290974e-01 ... 3.41272939e-03\n",
      "  1.68012889e-04 8.55777941e-06]\n",
      " [9.61424398e-03 2.41019755e-01 4.74460251e-01 ... 2.28148605e-03\n",
      "  1.53862644e-04 3.59720563e-06]\n",
      " [1.48247666e-02 4.65782909e-01 3.00848722e-01 ... 5.70894991e-03\n",
      "  1.74632155e-04 1.76412088e-06]]\n"
     ]
    }
   ],
   "source": [
    "y_data = np.loadtxt(\"dataset/y_dataTrain.txt\")\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ae16213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10003, 12)\n",
      "(10003, 4378)\n"
     ]
    }
   ],
   "source": [
    "print(y_data.shape)\n",
    "print(x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b078fef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict: {\n",
    "    0 : 'H2O',\n",
    "    1 : 'CO2',\n",
    "    2 : 'O2',\n",
    "    3 : 'N2',\n",
    "    4 : 'CH4',\n",
    "    5 : 'N2O',\n",
    "    6 : 'CO',\n",
    "    7 : 'O3',\n",
    "    8 : 'SO2',\n",
    "    9 : 'NH3',\n",
    "    10 : 'C2H6',\n",
    "    11 : 'NO2'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fefe89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_h2o = y_data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f13fe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_h2o, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07136181",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b318daa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▎                                                       | 1/42 [08:23<5:44:03, 503.50s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "---------------------------------------------------------------------------",
      "KeyboardInterrupt                         Traceback (most recent call last)",
      "Input In [9], in <cell line: 1>()\n----> 1 models, predictions = reg.fit(x_train, x_test, y_train, y_test)\n",
      "File ~/.local/opt/miniconda/envs/exo2/lib/python3.8/site-packages/lazypredict/Supervised.py:614, in LazyRegressor.fit(self, X_train, X_test, y_train, y_test)\n    609 else:\n    610     pipe = Pipeline(\n    611         steps=[(\"preprocessor\", preprocessor), (\"regressor\", model())]\n    612     )\n--> 614 pipe.fit(X_train, y_train)\n    615 self.models[name] = pipe\n    616 y_pred = pipe.predict(X_test)\n",
      "File ~/.local/opt/miniconda/envs/exo2/lib/python3.8/site-packages/sklearn/pipeline.py:335, in Pipeline.fit(self, X, y, **fit_params)\n    333     if self._final_estimator != 'passthrough':\n    334         fit_params_last_step = fit_params_steps[self.steps[-1][0]]\n--> 335         self._final_estimator.fit(Xt, y, **fit_params_last_step)\n    337 return self\n",
      "File ~/.local/opt/miniconda/envs/exo2/lib/python3.8/site-packages/sklearn/ensemble/_bagging.py:243, in BaseBagging.fit(self, X, y, sample_weight)\n    220 def fit(self, X, y, sample_weight=None):\n    221     \"\"\"Build a Bagging ensemble of estimators from the training\n    222        set (X, y).\n    223 \n   (...)\n    241     self : object\n    242     \"\"\"\n--> 243     return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "File ~/.local/opt/miniconda/envs/exo2/lib/python3.8/site-packages/sklearn/ensemble/_bagging.py:369, in BaseBagging._fit(self, X, y, max_samples, max_depth, sample_weight)\n    366 seeds = random_state.randint(MAX_INT, size=n_more_estimators)\n    367 self._seeds = seeds\n--> 369 all_results = Parallel(n_jobs=n_jobs, verbose=self.verbose,\n    370                        **self._parallel_args())(\n    371     delayed(_parallel_build_estimators)(\n    372         n_estimators[i],\n    373         self,\n    374         X,\n    375         y,\n    376         sample_weight,\n    377         seeds[starts[i]:starts[i + 1]],\n    378         total_n_estimators,\n    379         verbose=self.verbose)\n    380     for i in range(n_jobs))\n    382 # Reduce\n    383 self.estimators_ += list(itertools.chain.from_iterable(\n    384     t[0] for t in all_results))\n",
      "File ~/.local/opt/miniconda/envs/exo2/lib/python3.8/site-packages/joblib/parallel.py:1041, in Parallel.__call__(self, iterable)\n   1032 try:\n   1033     # Only set self._iterating to True if at least a batch\n   1034     # was dispatched. In particular this covers the edge\n   (...)\n   1038     # was very quick and its callback already dispatched all the\n   1039     # remaining jobs.\n   1040     self._iterating = False\n-> 1041     if self.dispatch_one_batch(iterator):\n   1042         self._iterating = self._original_iterator is not None\n   1044     while self.dispatch_one_batch(iterator):\n",
      "File ~/.local/opt/miniconda/envs/exo2/lib/python3.8/site-packages/joblib/parallel.py:859, in Parallel.dispatch_one_batch(self, iterator)\n    857     return False\n    858 else:\n--> 859     self._dispatch(tasks)\n    860     return True\n",
      "File ~/.local/opt/miniconda/envs/exo2/lib/python3.8/site-packages/joblib/parallel.py:777, in Parallel._dispatch(self, batch)\n    775 with self._lock:\n    776     job_idx = len(self._jobs)\n--> 777     job = self._backend.apply_async(batch, callback=cb)\n    778     # A job can complete so quickly than its callback is\n    779     # called before we get here, causing self._jobs to\n    780     # grow. To ensure correct results ordering, .insert is\n    781     # used (rather than .append) in the following line\n    782     self._jobs.insert(job_idx, job)\n",
      "File ~/.local/opt/miniconda/envs/exo2/lib/python3.8/site-packages/joblib/_parallel_backends.py:208, in SequentialBackend.apply_async(self, func, callback)\n    206 def apply_async(self, func, callback=None):\n    207     \"\"\"Schedule a func to be run\"\"\"\n--> 208     result = ImmediateResult(func)\n    209     if callback:\n    210         callback(result)\n",
      "File ~/.local/opt/miniconda/envs/exo2/lib/python3.8/site-packages/joblib/_parallel_backends.py:572, in ImmediateResult.__init__(self, batch)\n    569 def __init__(self, batch):\n    570     # Don't delay the application, to avoid keeping the input\n    571     # arguments in memory\n--> 572     self.results = batch()\n",
      "File ~/.local/opt/miniconda/envs/exo2/lib/python3.8/site-packages/joblib/parallel.py:262, in BatchedCalls.__call__(self)\n    258 def __call__(self):\n    259     # Set the default nested backend to self._backend but do not set the\n    260     # change the default number of processes to -1\n    261     with parallel_backend(self._backend, n_jobs=self._n_jobs):\n--> 262         return [func(*args, **kwargs)\n    263                 for func, args, kwargs in self.items]\n",
      "File ~/.local/opt/miniconda/envs/exo2/lib/python3.8/site-packages/joblib/parallel.py:262, in <listcomp>(.0)\n    258 def __call__(self):\n    259     # Set the default nested backend to self._backend but do not set the\n    260     # change the default number of processes to -1\n    261     with parallel_backend(self._backend, n_jobs=self._n_jobs):\n--> 262         return [func(*args, **kwargs)\n    263                 for func, args, kwargs in self.items]\n",
      "File ~/.local/opt/miniconda/envs/exo2/lib/python3.8/site-packages/sklearn/ensemble/_bagging.py:110, in _parallel_build_estimators(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose)\n    107         not_indices_mask = ~indices_to_mask(indices, n_samples)\n    108         curr_sample_weight[not_indices_mask] = 0\n--> 110     estimator.fit(X[:, features], y, sample_weight=curr_sample_weight)\n    112 else:\n    113     estimator.fit((X[indices])[:, features], y[indices])\n",
      "File ~/.local/opt/miniconda/envs/exo2/lib/python3.8/site-packages/sklearn/tree/_classes.py:1242, in DecisionTreeRegressor.fit(self, X, y, sample_weight, check_input, X_idx_sorted)\n   1205 def fit(self, X, y, sample_weight=None, check_input=True,\n   1206         X_idx_sorted=None):\n   1207     \"\"\"Build a decision tree regressor from the training set (X, y).\n   1208 \n   1209     Parameters\n   (...)\n   1239         Fitted estimator.\n   1240     \"\"\"\n-> 1242     super().fit(\n   1243         X, y,\n   1244         sample_weight=sample_weight,\n   1245         check_input=check_input,\n   1246         X_idx_sorted=X_idx_sorted)\n   1247     return self\n",
      "File ~/.local/opt/miniconda/envs/exo2/lib/python3.8/site-packages/sklearn/tree/_classes.py:375, in BaseDecisionTree.fit(self, X, y, sample_weight, check_input, X_idx_sorted)\n    366 else:\n    367     builder = BestFirstTreeBuilder(splitter, min_samples_split,\n    368                                    min_samples_leaf,\n    369                                    min_weight_leaf,\n   (...)\n    372                                    self.min_impurity_decrease,\n    373                                    min_impurity_split)\n--> 375 builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)\n    377 if self.n_outputs_ == 1 and is_classifier(self):\n    378     self.n_classes_ = self.n_classes_[0]\n",
      "KeyboardInterrupt: "
     ]
    }
   ],
   "source": [
    "models, predictions = reg.fit(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af9991e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnls_model = linear_model.LinearRegression(positive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ffafb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnls_predictions = nnls_model.fit(x_train, y_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9047127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: -0.00042679640950304965\n"
     ]
    }
   ],
   "source": [
    "print(\"R2 score:\", r2_score(y_test, nnls_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
